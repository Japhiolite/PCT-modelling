{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os,sys\n",
    "from scipy import stats\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../models/20210219_MC_ensemble/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rejection algorithm based on random walk\n",
    "We created a tiny ensemble of 100 different SHEMAT-Suite and will use a rejection algorithm based on the Metropolis acceptance probability to get a posterior ensemble of models.  \n",
    "The Metropolis acceptance probability is defined as:  \n",
    "\n",
    "$$ \\alpha(x_{t-1},z) = \\begin{cases} min\\big(\\frac{p(z)}{p(x_{t-1})},1\\big), & \\text{if } p(x_{t-1}) > 0\\\\\n",
    "1, & \\text{if } p(x_{t-1}) = 0 \\end{cases} $$  \n",
    "\n",
    "A different approach would be to assess the missfit (as RMS error) of each realisation.  \n",
    "\n",
    "$$ \\alpha(x_{t-1},z) = \\begin{cases} exp\\big(-\\frac{S(z) - S(x_{t-1}) }{u_T}\\big), & \\text{if } S(z) > S(x_{t-1})\\\\\n",
    "1, & \\text{otherwise }  \\end{cases} $$  \n",
    "\n",
    "We will use the second approach for now...also because we wrote it in the abstract.  \n",
    "As discretization error, we take a value from Elison(2015), $u_{T-discr} = 0.7$ K  \n",
    "\n",
    "Using Gauss error propagation, we assess a potential error for the realisations.  \n",
    "\n",
    "$$ u_T = \\sqrt{\\big(\\frac{\\partial T}{\\partial x_1}u_1 \\big)^2 + ... + \\big(\\frac{\\partial T}{\\partial x_n}u_n \\big)^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literature sources for log-errors:\n",
    "_The lower part of the disturbed log profile (below the cross-over point) was rotated to match these corrected tempera-tures. In the upper part of the profile, the same correction as for method A was applied. The quality of this correction method strongly depends on the correct calculation of the lowermost profile temperatures. According to Förster (2001), most of the corrected tem-peratures have errors of ± 3 to 5 K._ https://doi.org/10.1186/s40517-020-00181-w  \n",
    "\n",
    "\n",
    " _The effective accuracy of commercial temperature logs is ±0.5ºC (Blackwell and Spafford, 1987)._  http://www.sprensky.com/publishd/temper2.html  \n",
    " \n",
    " _More normal accuracies are +- 0.25 °C over 0-200 °C_ Keith Geothermal Energy lecture  \n",
    " \n",
    " For errors as a function of e.g. logging speed, measurement response time etc, look https://doi.org/10.1016/j.petrol.2020.107727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fahrenheit_to_celsius(temp_fahrenheit, difference=False):\n",
    "    if not difference:\n",
    "        return (temp_fahrenheit - 32) * 5 / 9\n",
    "    else:\n",
    "        return temp_fahrenheit * 5 / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4237296698599444\n"
     ]
    }
   ],
   "source": [
    "# define uT\n",
    "T_error = 0.25 # temperature error tool accuracy\n",
    "s_error = fahrenheit_to_celsius(1.25, difference=True) # sensor response time of 2 sec and 1 year after drilling\n",
    "l_error = fahrenheit_to_celsius(1.25, difference=True) # logging speed of 20/ft after 1 year\n",
    "d_error = 1.0 # estimated temperature error by discretization\n",
    "#u_T = np.sqrt(T_error[0]**2 + T_error[1]**2 + T_error[2]**2 + T_error[3]**2 + d_error**2)\n",
    "#u_T = np.sum(T_error**2)/4\n",
    "u_T = np.sqrt(T_error**2 + s_error**2 + l_error**2 + d_error**2)\n",
    "print(u_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Simulation outputs. Those outputs get written by SHEMAT-Suite if runmode = 1\n",
    "outp_path = '../models/20210219_MC_ensemble/'\n",
    "diffs = np.loadtxt(outp_path+'PCT_MC_0var_TCt_final.dat',skiprows=3,usecols=(8,),dtype=float)\n",
    "for i in range(1,100):\n",
    "    n = np.loadtxt(outp_path+f'PCT_MC_{i}var_TCt_final.dat',skiprows=3,usecols=(8,),dtype=float)\n",
    "    diffs=np.vstack([diffs,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE of each realisation.\n",
    "n = diffs.shape[1] # as we have 4 data points for temperature\n",
    "\n",
    "diffs_sq = diffs**2\n",
    "ssr = diffs_sq.sum(axis=1)\n",
    "rmse = np.sqrt((diffs_sq.sum(axis=1)/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 98)\n"
     ]
    }
   ],
   "source": [
    "# this is a matrix with all vectors. First 96 columns are differences of the wells, then the column is the SSR, \n",
    "# final column is RMSE\n",
    "tot_diffs = np.column_stack((diffs,ssr,rmse))\n",
    "print(tot_diffs.shape)\n",
    "# add index to the realizations\n",
    "ind = np.array(range(100))\n",
    "tot_diffs = np.column_stack((tot_diffs,ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.5201195, -1.461665 , -1.403697 , -1.3462403, -1.2893066,\n",
       "       -1.2328994, -1.177    , -1.1215621, -1.0665283, -1.0118893,\n",
       "       -0.957759 , -0.9043045, -0.8516312, -0.799683 , -0.7481756,\n",
       "       -0.6966115, -0.6445547, -0.5926642, -0.5419091, -0.4931279,\n",
       "       -0.4469584, -0.4038413, -0.3639712, -0.3270807, -0.2918596,\n",
       "       -0.2546062, -0.2212619, -0.1942998, -0.1707273, -0.1490087,\n",
       "       -0.1283688, -0.1085283, -0.0957589, -0.0855443, -0.0741754,\n",
       "       -0.0614251, -0.0469003, -0.03273  , -0.0189854, -1.1048345,\n",
       "       -1.0635816, -1.0211166, -0.977543 , -0.9329919, -0.8876188,\n",
       "       -0.8415941, -0.7950881, -0.7482432, -0.7011275, -0.6536518,\n",
       "       -0.5966005, -0.5482866, -0.5098773, -0.4639739, -0.4102419,\n",
       "       -0.3501038, -0.2919517, -0.2353215, -0.1797906, -0.1273862,\n",
       "       -0.077933 , -3.460852 , -3.133596 , -2.793566 , -2.453768 ,\n",
       "       -2.070575 , -1.814628 , -1.662045 , -1.458957 , -1.241025 ,\n",
       "       -1.042408 , -0.86238  , -0.691421 , -0.527159 , -0.368137 ,\n",
       "       -0.213537 , -0.062645 ,  0.021962 ,  0.04135  ,  0.059499 ,\n",
       "        0.076336 ,  0.091814 ,  0.1059437,  0.1187639,  0.1303114,\n",
       "        0.1406065,  0.1496642,  0.1506619,  0.143953 ,  0.134227 ,\n",
       "        0.1216149,  0.1057818,  0.0868657,  0.0677845,  0.0486537,\n",
       "        0.0295759])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs[0,:] - diffs[72,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection sampling\n",
    "we now start with a random sample and go randomly through the pool, accepting and rejecting realizations.\n",
    "The algorithm starts with one refrence sample `Ref`. Then, iteratively, samples (= realizations) get accepted, rejected based on their RMSE values. That is why we use the 6th column of `tot_diffs`. Alternatively, one could also just use the `rmse` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ba7ba6a3a6da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_diffs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mRef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'col' is not defined"
     ]
    }
   ],
   "source": [
    "np.exp(-(tot_diffs[65,col] - Ref)/(u_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "[1, 4, 6, 8, 9, 10, 13, 19, 23, 24, 32, 34, 36, 37, 38, 39, 41, 43, 44, 50, 56, 57, 64, 66, 71, 78, 79, 81, 84, 85, 93, 96, 97]\n"
     ]
    }
   ],
   "source": [
    "# Chronological implemntation - start von 1 bis N \n",
    "# Can be used here, if samples generated are already in a random order and not correlated.\n",
    "# That is usually the case with GemPy exports to SHEMAT-Suite.\n",
    "col = 97\n",
    "Ref = tot_diffs[0,col]\n",
    "accept = []\n",
    "P = []\n",
    "k=0\n",
    "for i in range(1,100):\n",
    "    if tot_diffs[i,col] < Ref:\n",
    "        Ref = tot_diffs[i,col]\n",
    "        accept.append(i)\n",
    "        \n",
    "    elif random.random() < np.exp(-(tot_diffs[i,col] - Ref)/(u_T)):\n",
    "        P.append(np.exp(-(tot_diffs[i,col] - Ref)/(u_T)))\n",
    "        Ref = tot_diffs[i,col]\n",
    "        accept.append(i)\n",
    "        k += 1\n",
    "print(len(accept))\n",
    "print(accept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we see, temperature data is not sensitive to changes in the PCT-depth.  \n",
    "\n",
    "But what if we also treat the thermal conductivity as an uncertain parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Then the rejection is way more rigorous.*"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:env_datasci]",
   "language": "python",
   "name": "conda-env-env_datasci-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
